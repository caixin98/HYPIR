"""Training script for TiTok.

Copyright (2024) Bytedance Ltd. and/or its affiliates

Licensed under the Apache License, Version 2.0 (the "License"); 
you may not use this file except in compliance with the License. 
You may obtain a copy of the License at 

    http://www.apache.org/licenses/LICENSE-2.0 

Unless required by applicable law or agreed to in writing, software 
distributed under the License is distributed on an "AS IS" BASIS, 
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
See the License for the specific language governing permissions and 
limitations under the License.

Reference:
    https://github.com/huggingface/open-muse
"""
import math
import os
import argparse
from pathlib import Path
import json

from accelerate.utils import set_seed
from accelerate import Accelerator

import torch
from omegaconf import OmegaConf
from utils.logger import setup_logger
from data.piat_loader import create_train_dataloader, create_val_dataloader
from utils.train_utils import (
    get_config, create_clip_model, 
    create_model_and_loss_module,
    create_optimizer, create_lr_scheduler, create_dataloader,
    create_evaluator, auto_resume, save_checkpoint, 
    train_one_epoch,
    reconstruct_images,
    validate_noise_injection_config,
)
from modeling.modules.ema_model import EMAModel
from accelerate.utils import DistributedDataParallelKwargs

def monitor_encoder_gradients(model, logger, step, model_type="srtitok"):
    """ç›‘æ§encoderçš„æ¢¯åº¦çŠ¶æ€"""
    if model_type != "srtitok":
        return
    
    # è·å–æ¨¡å‹ï¼ˆå¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒï¼‰
    if hasattr(model, 'module'):
        actual_model = model.module
    else:
        actual_model = model
    
    # æ£€æŸ¥æ˜¯å¦æœ‰encoder
    if not hasattr(actual_model, 'encoder') or actual_model.encoder is None:
        logger.info(f"Step {step}: è·³è¿‡encoderè®­ç»ƒ (skip_encoder=True)")
        return
    
    # æ£€æŸ¥encoderå‚æ•°
    encoder_params = list(actual_model.encoder.parameters())
    if not encoder_params:
        logger.info(f"Step {step}: Encoderæ²¡æœ‰å¯è®­ç»ƒå‚æ•°")
        return
    
    # æ£€æŸ¥æ¢¯åº¦çŠ¶æ€
    total_grad_norm = 0.0
    param_count = 0
    has_grad = False
    
    for param in encoder_params:
        if param.grad is not None:
            has_grad = True
            grad_norm = param.grad.norm().item()
            total_grad_norm += grad_norm ** 2
            param_count += 1
    
    if has_grad:
        avg_grad_norm = (total_grad_norm ** 0.5) / max(param_count, 1)
        logger.info(f"Step {step}: Encoderæ¢¯åº¦æ­£å¸¸ - å‚æ•°æ•°: {param_count}, å¹³å‡æ¢¯åº¦èŒƒæ•°: {avg_grad_norm:.6f}")
    else:
        logger.warning(f"Step {step}: âš ï¸ Encoderæ²¡æœ‰æ¢¯åº¦ï¼")
    
    # æ£€æŸ¥encoderæ˜¯å¦å¤„äºè®­ç»ƒæ¨¡å¼
    if actual_model.encoder.training:
        logger.info(f"Step {step}: Encoderå¤„äºè®­ç»ƒæ¨¡å¼")
    else:
        logger.warning(f"Step {step}: âš ï¸ Encoderå¤„äºè¯„ä¼°æ¨¡å¼ï¼")


def monitor_decoder_gradients(model, logger, step, model_type="srtitok"):
    """ç›‘æ§decoderçš„æ¢¯åº¦çŠ¶æ€"""
    if model_type != "srtitok":
        return
    
    # è·å–æ¨¡å‹ï¼ˆå¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒï¼‰
    if hasattr(model, 'module'):
        actual_model = model.module
    else:
        actual_model = model
    
    # æ£€æŸ¥æ˜¯å¦æœ‰decoder
    if not hasattr(actual_model, 'decoder') or actual_model.decoder is None:
        logger.error(f"Step {step}: æ¨¡å‹æ²¡æœ‰decoderï¼")
        return
    
    # æ£€æŸ¥decoderå‚æ•°
    decoder_params = list(actual_model.decoder.parameters())
    if not decoder_params:
        logger.info(f"Step {step}: Decoderæ²¡æœ‰å¯è®­ç»ƒå‚æ•°")
        return
    
    # æ£€æŸ¥æ¢¯åº¦çŠ¶æ€
    total_grad_norm = 0.0
    param_count = 0
    has_grad = False
    
    for param in decoder_params:
        if param.grad is not None:
            has_grad = True
            grad_norm = param.grad.norm().item()
            total_grad_norm += grad_norm ** 2
            param_count += 1
    
    if has_grad:
        avg_grad_norm = (total_grad_norm ** 0.5) / max(param_count, 1)
        logger.info(f"Step {step}: Decoderæ¢¯åº¦æ­£å¸¸ - å‚æ•°æ•°: {param_count}, å¹³å‡æ¢¯åº¦èŒƒæ•°: {avg_grad_norm:.6f}")
    else:
        logger.warning(f"Step {step}: âš ï¸ Decoderæ²¡æœ‰æ¢¯åº¦ï¼")
    
    # æ£€æŸ¥decoderæ˜¯å¦å¤„äºè®­ç»ƒæ¨¡å¼
    if actual_model.decoder.training:
        logger.info(f"Step {step}: Decoderå¤„äºè®­ç»ƒæ¨¡å¼")
    else:
        logger.warning(f"Step {step}: âš ï¸ Decoderå¤„äºè¯„ä¼°æ¨¡å¼ï¼")
    
    # æ£€æŸ¥decoderç±»å‹ä¿¡æ¯
    if hasattr(actual_model, 'decoder_type'):
        logger.info(f"Step {step}: Decoderç±»å‹: {actual_model.decoder_type}")
    
    # æ£€æŸ¥æ˜¯å¦åªå¾®è°ƒdecoder
    if hasattr(actual_model, 'finetune_decoder'):
        if actual_model.finetune_decoder:
            logger.info(f"Step {step}: ä»…å¾®è°ƒdecoderæ¨¡å¼")
        else:
            logger.info(f"Step {step}: æ­£å¸¸è®­ç»ƒæ¨¡å¼")


def monitor_z_params_stats(model, logger, step, model_type="srtitok"):
    """ç›‘æ§z paramsçš„ç»Ÿè®¡é‡"""
    if model_type != "srtitok":
        return None
    
    # è·å–æ¨¡å‹ï¼ˆå¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒï¼‰
    if hasattr(model, 'module'):
        actual_model = model.module
    else:
        actual_model = model
    
    # æ£€æŸ¥æ˜¯å¦æœ‰encoderå’Œimage_z_quantized_params
    if not hasattr(actual_model, 'encoder') or actual_model.encoder is None:
        logger.info(f"Step {step}: è·³è¿‡z paramsç›‘æ§ (æ²¡æœ‰encoder)")
        return None
    
    if not hasattr(actual_model.encoder, 'image_z_quantized_params'):
        logger.info(f"Step {step}: è·³è¿‡z paramsç›‘æ§ (æ²¡æœ‰image_z_quantized_params)")
        return None
    
    # è·å–z params
    z_params = actual_model.encoder.image_z_quantized_params
    
    if z_params is None:
        logger.warning(f"Step {step}: âš ï¸ image_z_quantized_paramsä¸ºNone")
        return None
    
    # è®¡ç®—ç»Ÿè®¡é‡
    with torch.no_grad():
        # åŸºæœ¬ç»Ÿè®¡é‡
        z_mean = z_params.mean().item()
        z_std = z_params.std().item()
        z_min = z_params.min().item()
        z_max = z_params.max().item()
        z_norm = z_params.norm().item()
        
        # è®¡ç®—éé›¶å‚æ•°çš„æ¯”ä¾‹
        z_nonzero = (z_params != 0).float().mean().item()
        
        # # è®¡ç®—å‚æ•°åˆ†å¸ƒï¼ˆåˆ†ä½æ•°ï¼‰
        # z_25 = torch.quantile(z_params, 0.25).item()
        # z_50 = torch.quantile(z_params, 0.50).item()
        # z_75 = torch.quantile(z_params, 0.75).item()
        
        # è®¡ç®—å‚æ•°å˜åŒ–ï¼ˆå¦‚æœä¹‹å‰æœ‰è®°å½•ï¼‰
        if not hasattr(monitor_z_params_stats, 'prev_z_params'):
            monitor_z_params_stats.prev_z_params = z_params.clone()
            z_change = 0.0
        else:
            z_change = (z_params - monitor_z_params_stats.prev_z_params).norm().item()
            monitor_z_params_stats.prev_z_params = z_params.clone()
    
    # è®°å½•ç»Ÿè®¡ä¿¡æ¯
    logger.info(f"Step {step}: Z Paramsç»Ÿè®¡é‡:")
    logger.info(f"  - å½¢çŠ¶: {z_params.shape}")
    logger.info(f"  - å‡å€¼: {z_mean:.6f}, æ ‡å‡†å·®: {z_std:.6f}")
    logger.info(f"  - èŒƒå›´: [{z_min:.6f}, {z_max:.6f}]")
    logger.info(f"  - èŒƒæ•°: {z_norm:.6f}")
    logger.info(f"  - éé›¶æ¯”ä¾‹: {z_nonzero:.4f}")
    logger.info(f"  - å‚æ•°å˜åŒ–: {z_change:.6f}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
    if z_std > 10.0:
        logger.warning(f"Step {step}: âš ï¸ Z paramsæ ‡å‡†å·®è¿‡å¤§: {z_std:.6f}")
    if z_norm > 1000.0:
        logger.warning(f"Step {step}: âš ï¸ Z paramsèŒƒæ•°è¿‡å¤§: {z_norm:.6f}")
    if z_nonzero < 0.1:
        logger.warning(f"Step {step}: âš ï¸ Z paramséé›¶æ¯”ä¾‹è¿‡ä½: {z_nonzero:.4f}")
    
    # å¦‚æœæ”¯æŒï¼Œè·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯
    if hasattr(actual_model, 'get_image_parameter_stats'):
        try:
            detailed_stats = actual_model.get_image_parameter_stats()
            logger.info(f"Step {step}: è¯¦ç»†å‚æ•°ç»Ÿè®¡: {detailed_stats}")
        except Exception as e:
            logger.warning(f"Step {step}: è·å–è¯¦ç»†å‚æ•°ç»Ÿè®¡å¤±è´¥: {e}")
    
    # è¿”å›ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼Œç”¨äºæ—¥å¿—è®°å½•
    stats_dict = {
        "z_params/mean": z_mean,
        "z_params/std": z_std,
        "z_params/min": z_min,
        "z_params/max": z_max,
        "z_params/norm": z_norm,
        "z_params/nonzero_ratio": z_nonzero,
        "z_params/change": z_change,
        "z_params/shape": str(z_params.shape),
    }
    
    return stats_dict


def main():
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="SR-TiTokè®­ç»ƒè„šæœ¬")
    parser.add_argument("--local_image_dir", type=str, default=None, help="æœ¬åœ°å›¾åƒç›®å½•è·¯å¾„ï¼ˆç”¨äºè¯„ä¼°ï¼‰")
    parser.add_argument("--local_eval_samples", type=int, default=100, help="æœ¬åœ°è¯„ä¼°æ ·æœ¬æ•°é‡")
    parser.add_argument("--local_train_image_dir", type=str, default=None, help="æœ¬åœ°è®­ç»ƒå›¾åƒç›®å½•è·¯å¾„")
    parser.add_argument("--local_train_samples", type=int, default=None, help="æœ¬åœ°è®­ç»ƒæ ·æœ¬æ•°é‡")
    # æ·»åŠ noiseæ³¨å…¥ç›¸å…³çš„å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument("--enable_noise_injection", action="store_true", help="å¯ç”¨noiseæ³¨å…¥æœºåˆ¶")
    parser.add_argument("--noise_strength", type=float, default=0.1, help="noiseæ³¨å…¥å¼ºåº¦ (0.0-1.0)")
    parser.add_argument("--noise_type", type=str, default="gaussian", choices=["gaussian", "uniform"], help="noiseç±»å‹")
    args, unknown = parser.parse_known_args()
    
    workspace = os.environ.get('WORKSPACE', '')
    if workspace:
        torch.hub.set_dir(workspace + "/models/hub")

    config = get_config()
    
    # å¦‚æœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ï¼Œè¦†ç›–é…ç½®ä¸­çš„è®¾ç½®
    if args.local_train_image_dir:
        if not hasattr(config, 'local_train'):
            config.local_train = {}
        config.local_train.enabled = True
        config.local_train.image_dir = args.local_train_image_dir
        config.local_train.max_samples = args.local_train_samples
    
    # å¤„ç†noiseæ³¨å…¥é…ç½®
    if args.enable_noise_injection:
        if not hasattr(config, 'noise_injection'):
            config.noise_injection = {}
        config.noise_injection.enabled = True
        config.noise_injection.strength = args.noise_strength
        config.noise_injection.type = args.noise_type
        logger.info(f"å¯ç”¨noiseæ³¨å…¥æœºåˆ¶ - å¼ºåº¦: {args.noise_strength}, ç±»å‹: {args.noise_type}")
    elif not hasattr(config, 'noise_injection'):
        # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œè®¾ç½®é»˜è®¤é…ç½®
        config.noise_injection = {
            'enabled': False,
            'strength': 0.1,
            'type': 'gaussian'
        }
    
    # Enable TF32 on Ampere GPUs.
    if config.training.enable_tf32:
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False

    output_dir = config.experiment.output_dir
    os.makedirs(output_dir, exist_ok=True)
    config.experiment.logging_dir = os.path.join(output_dir, "logs")

    # Whether logging to Wandb or Tensorboard.
    tracker = "tensorboard"
    if config.training.enable_wandb:
        tracker = "wandb"

    accelerator = Accelerator(
        gradient_accumulation_steps=config.training.gradient_accumulation_steps,
        mixed_precision=config.training.mixed_precision,
        log_with=tracker,
        project_dir=config.experiment.logging_dir,
        split_batches=False,
        kwargs_handlers=[DistributedDataParallelKwargs(find_unused_parameters=True)]
    )

    logger = setup_logger(name="SR-TiTok", log_level="INFO",
     output_file=f"{output_dir}/log{accelerator.process_index}.txt")

    # éªŒè¯noiseæ³¨å…¥é…ç½®ï¼ˆåœ¨loggeråˆ›å»ºä¹‹åï¼‰
    if not validate_noise_injection_config(config, logger):
        logger.error("Noiseæ³¨å…¥é…ç½®éªŒè¯å¤±è´¥ï¼Œé€€å‡ºè®­ç»ƒ")
        return

    # We need to initialize the trackers we use, and also store our configuration.
    # The trackers initializes automatically on the main process.
    if accelerator.is_main_process:
        accelerator.init_trackers(config.experiment.name)
        config_path = Path(output_dir) / "config.yaml"
        logger.info(f"Saving config to {config_path}")
        OmegaConf.save(config, config_path)
        logger.info(f"Config:\n{OmegaConf.to_yaml(config)}")

    # If passed along, set the training seed now.
    if config.training.seed is not None:
        set_seed(config.training.seed, device_specific=True)
        
    accelerator.wait_for_everyone()

    model, ema_model, loss_module = create_model_and_loss_module(
        config, logger, accelerator, model_type="srtitok")

    # åœ¨id_basedæ¨¡å¼ä¸‹ï¼Œéœ€è¦å…ˆè·å–è®­ç»ƒé›†çš„id listå¹¶æ›´æ–°æ¨¡å‹
    if hasattr(model, 'encoder_mode') and model.encoder_mode == "id_based":
        if accelerator.is_main_process:
            logger.info("æ£€æµ‹åˆ°id_basedæ¨¡å¼ï¼Œä½¿ç”¨é¢„å®šä¹‰çš„imageå‚æ•°é…ç½®")
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹åŒæ­¥
        accelerator.wait_for_everyone()
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­æ˜¯å¦æŒ‡å®šäº†id_list_file
        config_id_list_file = config.model.vq_model.get("id_list_file", None)
        if config_id_list_file and os.path.exists(config_id_list_file):
            if accelerator.is_main_process:
                logger.info(f"é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šäº†id_list_file: {config_id_list_file}")
                logger.info(f"æ¨¡å‹å·²è‡ªåŠ¨åŠ è½½image_id_listï¼ŒåŒ…å«{len(model.get_image_id_list())}ä¸ªid")
        else:
            if accelerator.is_main_process:
                logger.warning("é…ç½®æ–‡ä»¶ä¸­æœªæŒ‡å®šid_list_fileï¼Œæ¨¡å‹å°†ä½¿ç”¨ç©ºçš„image_id_list")
                logger.info(f"å½“å‰æ¨¡å‹æ”¯æŒçš„æœ€å¤§imageæ•°é‡: {config.model.vq_model.get('max_image_count', 10000)}")
        
        # æ˜¾ç¤ºå‚æ•°ç»Ÿè®¡ä¿¡æ¯
        if hasattr(model, 'get_image_parameter_stats'):
            stats = model.get_image_parameter_stats()
            logger.info(f"æ¨¡å‹å‚æ•°ç»Ÿè®¡: {stats}")
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹åŒæ­¥
        accelerator.wait_for_everyone()
        
        if accelerator.is_main_process:
            logger.info("id_basedæ¨¡å¼åˆå§‹åŒ–å®Œæˆ")

    optimizer, discriminator_optimizer = create_optimizer(config, logger, model, loss_module, model_type="srtitok")

    lr_scheduler, discriminator_lr_scheduler = create_lr_scheduler(
        config, logger, accelerator, optimizer, discriminator_optimizer)

    # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼ˆæ”¯æŒæœ¬åœ°å›¾åƒï¼‰

    
    if hasattr(config, 'local_train') and config.local_train.enabled:
        logger.info(f"ä½¿ç”¨æœ¬åœ°å›¾åƒè®­ç»ƒï¼Œå›¾åƒç›®å½•: {config.local_train.image_dir}")
        train_dataloader = create_train_dataloader(config)  # ä¼ é€’ä¸‹é‡‡æ ·å€ç‡å‚æ•°
        logger.info(f"æœ¬åœ°è®­ç»ƒæ ·æœ¬æ•°: {config.local_train.max_samples if config.local_train.max_samples else 'å…¨éƒ¨'}")
        
        # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„å‚æ•°
        local_batch_size = getattr(config.local_train, 'batch_size', config.dataloader.train.batch_size)
        local_num_workers = getattr(config.local_train, 'num_workers', config.dataloader.train.num_workers)
        logger.info(f"æœ¬åœ°è®­ç»ƒå‚æ•° - batch_size: {local_batch_size}, num_workers: {local_num_workers}")
    else:
        logger.info("ä½¿ç”¨S3è®­ç»ƒæ•°æ®åŠ è½½å™¨")
        train_dataloader = create_train_dataloader(config)
    
    # åˆ›å»ºè¯„ä¼°æ•°æ®åŠ è½½å™¨
    if hasattr(model, 'encoder_mode') and model.encoder_mode == "id_based":
        # åœ¨id_basedæ¨¡å¼ä¸‹ï¼Œä½¿ç”¨è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†è¿›è¡Œè¯„ä¼°
        logger.info("id_basedæ¨¡å¼ï¼šä½¿ç”¨è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†è¿›è¡Œè¯„ä¼°")
        
        # åˆ›å»ºè®­ç»ƒé›†çš„å­é›†ç”¨äºè¯„ä¼°
        if hasattr(config, 'local_train') and config.local_train.enabled:
            # ä½¿ç”¨æœ¬åœ°è®­ç»ƒé…ç½®åˆ›å»ºè¯„ä¼°æ•°æ®åŠ è½½å™¨
            eval_config = config.copy()
            # è®¾ç½®è¯„ä¼°æ ·æœ¬æ•°é‡ï¼Œé»˜è®¤ä½¿ç”¨è®­ç»ƒé›†çš„20%
            eval_samples = getattr(config.local_eval, 'max_samples', 
                                 getattr(config.local_train, 'max_samples', None))
            if eval_samples is None:
                # å¦‚æœæ²¡æœ‰è®¾ç½®eval_samplesï¼Œåˆ™ä½¿ç”¨è®­ç»ƒé›†çš„20%
                eval_samples = int(getattr(config.local_train, 'max_samples', 10000) * 0.2)
            
            eval_config.local_train.max_samples = eval_samples
            eval_config.local_train.batch_size = getattr(config.local_train, 'eval_batch_size', 
                                                      config.local_train.batch_size)
            eval_config.local_train.num_workers = getattr(config.local_train, 'eval_num_workers', 
                                                       config.local_train.num_workers)
            
            eval_dataloader = create_train_dataloader(eval_config)
            
            if accelerator.is_main_process:
                logger.info(f"è¯„ä¼°æ—¶å°†ä½¿ç”¨è®­ç»ƒé›†çš„å‰{eval_samples}ä¸ªæ ·æœ¬")
                logger.info(f"è¯„ä¼°batch_size: {eval_config.local_train.batch_size}")
                logger.info(f"è¯„ä¼°num_workers: {eval_config.local_train.num_workers}")
        else:
            # ä½¿ç”¨S3è®­ç»ƒæ•°æ®ï¼Œåˆ›å»ºå­é›†ç”¨äºè¯„ä¼°
            eval_config = config.copy()
            # è®¾ç½®è¯„ä¼°æ ·æœ¬æ•°é‡
            eval_samples = getattr(config, 'eval_samples', 1000)
            eval_config.experiment.max_train_examples = eval_samples
            
            eval_dataloader = create_train_dataloader(eval_config)
            
            if accelerator.is_main_process:
                logger.info(f"è¯„ä¼°æ—¶å°†ä½¿ç”¨è®­ç»ƒé›†çš„å‰{eval_samples}ä¸ªæ ·æœ¬")
    elif config.local_eval.enabled:
        logger.info(f"ä½¿ç”¨æœ¬åœ°å›¾åƒè¯„ä¼°ï¼Œå›¾åƒç›®å½•: {config.local_eval.image_dir}")
        eval_dataloader = create_val_dataloader(config)  # ä¼ é€’ä¸‹é‡‡æ ·å€ç‡å‚æ•°
        
        # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„å‚æ•°
        local_eval_batch_size = getattr(config.local_eval, 'batch_size', config.dataloader.val.batch_size)
        local_eval_num_workers = getattr(config.local_eval, 'num_workers', config.dataloader.val.num_workers)
        logger.info(f"æœ¬åœ°è¯„ä¼°å‚æ•° - batch_size: {local_eval_batch_size}, num_workers: {local_eval_num_workers}")
    else:
        logger.info("ä½¿ç”¨S3éªŒè¯æ•°æ®åŠ è½½å™¨")
        eval_dataloader = create_val_dataloader(config)

    # Set up evaluator.
    evaluator = create_evaluator(config, logger, accelerator)

    # Prepare everything with accelerator.
    logger.info("Preparing model, optimizer and dataloaders")
    # The dataloader are already aware of distributed training, so we don't need to prepare them.
    model, loss_module, optimizer, discriminator_optimizer, lr_scheduler, discriminator_lr_scheduler = accelerator.prepare(
        model, loss_module, optimizer, discriminator_optimizer, lr_scheduler, discriminator_lr_scheduler
    )

    if config.training.use_ema:
        ema_model.to(accelerator.device)

    # Initialize FLUX VAE if needed for sanity check
    flux_vae = None
    if config.model.get("use_flux_vae", False):
        from modeling.flux.flux_vae import FLUX_VAE
        flux_vae = FLUX_VAE()
        flux_vae.to(accelerator.device)
        # FLUX_VAE is not an nn.Module, so we need to set eval mode on the underlying vae
        flux_vae.vae.eval()
        for param in flux_vae.vae.parameters():
            param.requires_grad = False

    # === Sanity check: run one evaluation before training ===
    if accelerator.is_main_process:
        logger.info("Running sanity check evaluation before training...")
        batch = next(iter(train_dataloader))
        reconstruct_images(
            model,
            batch['image'][:config.training.num_generated_images],
        batch['__key__'][:config.training.num_generated_images],
        accelerator,
        0,  # global_step
        config.experiment.output_dir,
        logger=logger,
        config=config,
        model_type="srtitok",
        cond_images=batch['cond_image'][:config.training.num_generated_images],
        flux_vae=flux_vae
        )
        logger.info("Sanity check evaluation done.")
    # === End sanity check ===

    total_batch_size_without_accum = config.training.per_gpu_batch_size * accelerator.num_processes
    num_batches = math.ceil(
        config.experiment.max_train_examples / total_batch_size_without_accum)
    num_update_steps_per_epoch = math.ceil(num_batches / config.training.gradient_accumulation_steps)
    num_train_epochs = math.ceil(config.training.max_train_steps / num_update_steps_per_epoch)

    # Start training.
    logger.info("***** Running training *****")
    logger.info(f"  Num training steps = {config.training.max_train_steps}")
    logger.info(f"  Gradient Accumulation steps = {config.training.gradient_accumulation_steps}")
    logger.info(f"  Instantaneous batch size per gpu = { config.training.per_gpu_batch_size}")
    logger.info(f"""  Total train batch size (w. parallel, distributed & accumulation) = {(
        config.training.per_gpu_batch_size *
        accelerator.num_processes *
        config.training.gradient_accumulation_steps)}""")
    if hasattr(config, 'local_train') and config.local_train.enabled:
        logger.info(f"  æœ¬åœ°å›¾åƒè®­ç»ƒ: å¯ç”¨ï¼Œå›¾åƒç›®å½•: {config.local_train.image_dir}")
        logger.info(f"  æœ¬åœ°è®­ç»ƒæ ·æœ¬æ•°: {config.local_train.max_samples if config.local_train.max_samples else 'å…¨éƒ¨'}")
    if config.local_eval.enabled:
        logger.info(f"  æœ¬åœ°å›¾åƒè¯„ä¼°: å¯ç”¨ï¼Œå›¾åƒç›®å½•: {config.local_eval.image_dir}")
        logger.info(f"  æœ¬åœ°è¯„ä¼°æ ·æœ¬æ•°: {config.local_eval.max_samples}")
    
    # æ˜¾ç¤ºnoiseæ³¨å…¥é…ç½®ä¿¡æ¯
    if config.noise_injection.enabled:
        logger.info(f"  ğŸ”Š Noiseæ³¨å…¥: å¯ç”¨ï¼Œå¼ºåº¦: {config.noise_injection.strength}, ç±»å‹: {config.noise_injection.type}")
    else:
        logger.info(f"  ğŸ”‡ Noiseæ³¨å…¥: ç¦ç”¨")
    

    # æ˜¾ç¤ºencoderè·³è¿‡ä¿¡æ¯
    if config.model.vq_model.get("skip_encoder", False):
        logger.info(f"  âš ï¸ è·³è¿‡encoderè®­ç»ƒ: åªè®­ç»ƒdecoder")
    else:
        logger.info(f"  âœ… æ­£å¸¸è®­ç»ƒ: encoder + decoder")
    global_step = 0
    first_epoch = 0

    global_step, first_epoch = auto_resume(
        config, logger, accelerator, ema_model, num_update_steps_per_epoch,
        strict=True)

    # Reset discriminator learning rate after loading checkpoint
    if discriminator_optimizer is not None:
        old_lr = discriminator_optimizer.param_groups[0]['lr']
        discriminator_optimizer.param_groups[0]['lr'] = config.optimizer.params.discriminator_learning_rate
        logger.info(f"Reset discriminator learning rate from {old_lr} to {discriminator_optimizer.param_groups[0]['lr']}")
        
        # # Also reset discriminator lr scheduler if it exists
        # if discriminator_lr_scheduler is not None:
        #     logger.info("Discriminator lr scheduler exists, but will be skipped due to lr=0")

    for current_epoch in range(first_epoch, num_train_epochs):
        accelerator.print(f"Epoch {current_epoch}/{num_train_epochs-1} started.")
        global_step = train_one_epoch(config, logger, accelerator,
                            model, ema_model, loss_module,
                            optimizer, discriminator_optimizer,
                            lr_scheduler, discriminator_lr_scheduler,
                            train_dataloader, eval_dataloader,
                            evaluator,
                            global_step,
                            model_type="srtitok",
                            flux_vae=flux_vae
                            )
        # Stop training if max steps is reached.
        if global_step >= config.training.max_train_steps:
            accelerator.print(
                f"Finishing training: Global step is >= Max train steps: {global_step} >= {config.training.max_train_steps}"
            )
            break

    accelerator.wait_for_everyone()
    # Save checkpoint at the end of training.
    save_checkpoint(model, output_dir, accelerator, global_step, logger=logger, config=config)
    # Save the final trained checkpoint
    if accelerator.is_main_process:
        model = accelerator.unwrap_model(model)
        if config.training.use_ema:
            ema_model.copy_to(model.parameters())
        model.save_pretrained_weight(output_dir)
    accelerator.end_training()


if __name__ == "__main__":
    main()