import math
import os
import random
import torch
from PIL import Image
from torch.utils.data import Dataset, Sampler, DataLoader
import torchvision.transforms as T


def create_aspect_ratio_buckets(base_size=1024, multiple_of=32, max_ratio_error=0.2):
    """
    ç”ŸæˆåŸºäºå®½é«˜æ¯”çš„æ¡¶åˆ—è¡¨ã€‚
    æ¨¡æ‹Ÿ 'preserve-area' é€»è¾‘ã€‚
    
    Args:
        base_size: åŸºç¡€å°ºå¯¸
        multiple_of: å°ºå¯¸å¿…é¡»æ˜¯è¯¥æ•°çš„å€æ•°
        max_ratio_error: æœ€å¤§æ¯”ä¾‹è¯¯å·®é˜ˆå€¼
    
    Returns:
        list: æ’åºåçš„ (width, height) æ¡¶åˆ—è¡¨
    """
    buckets = []
    target_area = base_size * base_size
    
    # éå†å¯èƒ½çš„å®½åº¦å’Œé«˜åº¦ï¼Œç¡®ä¿æ˜¯multiple_ofçš„å€æ•°
    for w in range(multiple_of, (base_size * 2) + 1, multiple_of):
        for h in range(multiple_of, (base_size * 2) + 1, multiple_of):
            area = w * h
            # è®¡ç®—ä¸ç›®æ ‡é¢ç§¯çš„è¯¯å·®
            error = abs(area - target_area)
            buckets.append({'width': w, 'height': h, 'error': error})

    # æŒ‰è¯¯å·®æ’åºæ‰¾åˆ°æœ€ä½³æ‹Ÿåˆçš„æ¡¶
    buckets.sort(key=lambda x: x['error'])
    
    # è¿‡æ»¤æ‰è¯¯å·®è¿‡é«˜çš„æ¡¶ä»¥ä¿æŒåˆ—è¡¨å¯ç®¡ç†
    max_allowed_error = buckets[int(len(buckets) * max_ratio_error)]['error']
    
    # ä½¿ç”¨é›†åˆå­˜å‚¨å”¯ä¸€çš„ (width, height) å…ƒç»„ä»¥é¿å…é‡å¤
    final_buckets = set()
    for bucket in buckets:
        if bucket['error'] <= max_allowed_error:
            final_buckets.add((bucket['width'], bucket['height']))

    # æŒ‰å®½é«˜æ¯”æ’åºæœ€ç»ˆæ¡¶
    sorted_buckets = sorted(list(final_buckets), key=lambda x: x[0] / x[1])
    
    print(f"âœ… åˆ›å»ºäº† {len(sorted_buckets)} ä¸ªæ¡¶")
    return sorted_buckets


def get_all_image_files(folder_path):
    """
    é€’å½’è·å–æ–‡ä»¶å¤¹åŠå…¶å­æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    
    Args:
        folder_path: æ ¹æ–‡ä»¶å¤¹è·¯å¾„
    
    Returns:
        list: æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶çš„å®Œæ•´è·¯å¾„åˆ—è¡¨
    """
    image_extensions = {'.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.PNG', '.JPG', '.JPEG', '.BMP', '.TIFF'}
    image_files = []
    
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if any(file.lower().endswith(ext.lower()) for ext in image_extensions):
                file_path = os.path.join(root, file)
                image_files.append(file_path)
    image_files.sort()
    return image_files


class AspectRatioBucketDataset(Dataset):
    """åŸºäºå®½é«˜æ¯”æ¡¶çš„æ•°æ®é›†ç±»"""
    
    def __init__(self, image_folder_path, buckets, max_samples=None):
        """
        Args:
            image_folder_path: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆæ”¯æŒé€’å½’éå†å­æ–‡ä»¶å¤¹ï¼‰
            buckets: æ¡¶åˆ—è¡¨
            max_samples: æœ€å¤§å›¾åƒæ•°é‡ï¼Œç”¨äºoverfittingæ—¶é™åˆ¶æ•°æ®é›†å¤§å°
        """
        self.image_folder_path = image_folder_path
        self.buckets = buckets
        self.max_samples = max_samples
        
        # é€’å½’è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        print(f"æ­£åœ¨æ‰«ææ–‡ä»¶å¤¹: {image_folder_path}")
        self.image_files = get_all_image_files(image_folder_path)
        
        # å¦‚æœæŒ‡å®šäº†max_samplesï¼Œåˆ™åªä½¿ç”¨å‰Nå¼ å›¾åƒ
        if self.max_samples is not None and self.max_samples > 0:
            self.image_files = self.image_files[:self.max_samples]
            print(f"ğŸ”’ Overfittingæ¨¡å¼ï¼šé™åˆ¶ä½¿ç”¨å‰ {self.max_samples} å¼ å›¾åƒ")
        
        self.image_data = []  # å­˜å‚¨ (filepath, bucket_id)
        
        print(f"é¢„è®¡ç®—å›¾ç‰‡å®½é«˜æ¯”å¹¶åˆ†é…æ¡¶... æ‰¾åˆ° {len(self.image_files)} å¼ å›¾ç‰‡")
        for filepath in self.image_files:
            try:
                # è·å–å›¾ç‰‡å°ºå¯¸è€Œä¸åŠ è½½å®Œæ•´å›¾ç‰‡
                with Image.open(filepath) as img:
                    width, height = img.size
                
                aspect_ratio = width / height
                
                # æ‰¾åˆ°æœ€é€‚åˆçš„æ¡¶
                best_bucket_id = min(
                    range(len(buckets)), 
                    key=lambda i: abs(aspect_ratio - (buckets[i][0] / buckets[i][1]))
                )
                
                self.image_data.append({
                    'filepath': filepath,
                    'bucket_id': best_bucket_id
                })
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•å¤„ç†å›¾ç‰‡ {filepath}: {e}")
                continue
            
    def __len__(self):
        return len(self.image_data)
        
    def __getitem__(self, index):
        # åªè¿”å›å…ƒæ•°æ®ï¼›å®é™…çš„åŠ è½½å’Œè°ƒæ•´å¤§å°å°†åœ¨ collate_fn ä¸­è¿›è¡Œ
        return self.image_data[index]


class AspectRatioBucketSampler(Sampler):
    """åŸºäºå®½é«˜æ¯”æ¡¶çš„é‡‡æ ·å™¨"""
    
    def __init__(self, dataset, batch_size, drop_last=False, shuffle=True):
        """
        Args:
            dataset: æ•°æ®é›†
            batch_size: æ‰¹æ¬¡å¤§å°
            drop_last: æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡
            shuffle: æ˜¯å¦éšæœºåŒ–é¡ºåºï¼ŒTrueä¸ºè®­ç»ƒæ¨¡å¼ï¼ŒFalseä¸ºéªŒè¯æ¨¡å¼
        """
        self.dataset = dataset
        self.batch_size = batch_size
        self.drop_last = drop_last
        self.shuffle = shuffle
        # æŒ‰ bucket_id åˆ†ç»„ç´¢å¼•
        self.buckets_to_indices = {}
        for idx, data in enumerate(dataset.image_data):
            bucket_id = data['bucket_id']
            if bucket_id not in self.buckets_to_indices:
                self.buckets_to_indices[bucket_id] = []
            self.buckets_to_indices[bucket_id].append(idx)
            
        # åˆ›å»ºæ‰€æœ‰å¯èƒ½çš„æ‰¹æ¬¡
        self.batches = []
        for bucket_id in self.buckets_to_indices:
            indices = self.buckets_to_indices[bucket_id]
            if self.shuffle:
                random.shuffle(indices)  # åœ¨æ¡¶å†…éšæœºæ‰“ä¹±ç´¢å¼•ï¼ˆä»…è®­ç»ƒæ¨¡å¼ï¼‰
            
            for i in range(0, len(indices), batch_size):
                batch = indices[i:i + batch_size]
                if len(batch) < batch_size and self.drop_last:
                    continue
                self.batches.append(batch)
        
        # éšæœºæ‰“ä¹±æ‰¹æ¬¡æœ¬èº«ï¼Œä½¿è®­ç»ƒé¡ºåºéšæœºï¼ˆä»…è®­ç»ƒæ¨¡å¼ï¼‰
        if self.shuffle:
            random.shuffle(self.batches)
        
    def __iter__(self):
        return iter(self.batches)
        
    def __len__(self):
        return len(self.batches)


def resize_for_cropping_pil(pil_img, target_bucket_dims):
    """
    ä¿æŒåŸå§‹å®½é«˜æ¯”è¿›è¡Œç¼©æ”¾ï¼Œä½¿ç¼©æ”¾åçš„æœ€çŸ­è¾¹ç­‰äºç›®æ ‡æ¡¶çš„æœ€çŸ­è¾¹ã€‚
    
    Args:
        pil_img: PILå›¾ç‰‡å¯¹è±¡
        target_bucket_dims: ç›®æ ‡æ¡¶å°ºå¯¸ (width, height)
    
    Returns:
        PIL.Image: è°ƒæ•´å¤§å°åçš„å›¾ç‰‡
    """
    target_w, target_h = target_bucket_dims
    base_size = min(target_w, target_h)
    
    original_w, original_h = pil_img.size
    aspect_ratio = original_w / original_h

    # ä½¿ç”¨ç®€æ´çš„ max() é€»è¾‘å®ç° short-edge ç¼©æ”¾
    new_w = int(round(max(base_size * aspect_ratio, base_size)))
    new_h = int(round(max(base_size / aspect_ratio, base_size)))

    # ä½¿ç”¨é«˜è´¨é‡çš„ LANCZOS ç®—æ³•è¿›è¡Œç¼©æ”¾
    resized_img = pil_img.resize((new_w, new_h), resample=Image.Resampling.LANCZOS)
    return resized_img


def crop_pil(pil_img, target_dims):
    """
    ä¸­å¿ƒè£å‰ªé€»è¾‘ã€‚
    
    Args:
        pil_img: PILå›¾ç‰‡å¯¹è±¡
        target_dims: ç›®æ ‡å°ºå¯¸ (width, height)
    
    Returns:
        PIL.Image: è£å‰ªåçš„å›¾ç‰‡
    """
    target_w, target_h = target_dims
    img_w, img_h = pil_img.size

    # è®¡ç®—ä¸­å¿ƒè£å‰ªçš„åæ ‡
    left = (img_w - target_w) // 2
    top = (img_h - target_h) // 2
    right = left + target_w
    bottom = top + target_h
    
    cropped_img = pil_img.crop((left, top, right, bottom))
    return cropped_img


def create_cond_image(pil_image, downsample_factor=2, upsample_factor=1):
    """
    åˆ›å»ºå¯è°ƒèŠ‚ä¸‹é‡‡æ ·å€ç‡çš„æ¡ä»¶å›¾åƒ
    
    Args:
        pil_image (PIL.Image): åŸå§‹PILå›¾åƒ
        downsample_factor (int): ä¸‹é‡‡æ ·å€ç‡ï¼Œé»˜è®¤ä¸º2
        upsample_factor (int): ä¸Šé‡‡æ ·å€ç‡ï¼Œé»˜è®¤ä¸º1
    Returns:
        torch.Tensor: ä¸‹é‡‡æ ·çš„æ¡ä»¶å›¾åƒtensor (CxHxW)
    """
    # æ ¹æ®ä¸‹é‡‡æ ·å€ç‡è¿›è¡Œä¸‹é‡‡æ ·
    cond_width = pil_image.width // downsample_factor
    cond_height = pil_image.height // downsample_factor
    cond_pil = pil_image.resize((cond_width, cond_height), resample=Image.Resampling.BICUBIC)
    if upsample_factor > 1:
        cond_width = cond_width * upsample_factor
        cond_height = cond_height * upsample_factor
        cond_pil = cond_pil.resize((cond_width, cond_height), resample=Image.Resampling.BICUBIC)
    # è½¬æ¢å›tensor
    cond_tensor = T.ToTensor()(cond_pil)

    return cond_tensor


def create_collate_fn(buckets, downsample_factor=2, upsample_factor=1):
    """
    åˆ›å»º collate_fnï¼Œæ•´åˆ resize + crop çš„å®Œæ•´æµç¨‹ã€‚
    
    Args:
        buckets: æ¡¶åˆ—è¡¨
        downsample_factor (int): ä¸‹é‡‡æ ·å€ç‡ï¼Œé»˜è®¤ä¸º2
        upsample_factor (int): ä¸Šé‡‡æ ·å€ç‡ï¼Œé»˜è®¤ä¸º1
    Returns:
        function: collateå‡½æ•°
    """
    def collate_fn(batch):
        # 1. è·å–æ‰¹æ¬¡çš„æ¡¶ä¿¡æ¯
        bucket_id = batch[0]['bucket_id']
        target_dims = buckets[bucket_id]  # (width, height)

        processed_images = []
        processed_cond_images = []
        image_keys = []
        
        to_tensor_transform = T.Compose([
            T.ToTensor(),  # å°† PIL Image [0, 255] è½¬æ¢ä¸º Tensor [0.0, 1.0]
        ])

        # 2. å¯¹æ‰¹æ¬¡ä¸­çš„æ¯ä¸€å¼ å›¾ç‰‡æ‰§è¡Œ"å…ˆç¼©æ”¾ã€åè£å‰ª"
        for item in batch:
            try:
                pil_img = Image.open(item['filepath']).convert('RGB')
                
                # æ­¥éª¤ A: ä¿æŒæ¯”ä¾‹ç¼©æ”¾ï¼Œä¸ºè£å‰ªåšå‡†å¤‡
                intermediate_img = resize_for_cropping_pil(pil_img, target_dims)
                
                # æ­¥éª¤ B: è¿›è¡Œä¸­å¿ƒè£å‰ªï¼Œå¾—åˆ°æœ€ç»ˆå°ºå¯¸
                final_img = crop_pil(intermediate_img, target_dims)
                
                # æ­¥éª¤ C: è½¬æ¢ä¸º Tensor å¹¶å½’ä¸€åŒ–
                tensor_img = to_tensor_transform(final_img)
                
                # æ­¥éª¤ D: åˆ›å»ºæ¡ä»¶å›¾åƒï¼ˆä½¿ç”¨å¯è°ƒèŠ‚çš„ä¸‹é‡‡æ ·å€ç‡ï¼‰
                cond_tensor = create_cond_image(final_img, downsample_factor=downsample_factor, upsample_factor=upsample_factor)
           
                # æ­¥éª¤ E: ç”Ÿæˆå›¾åƒé”®
                image_key = os.path.splitext(os.path.basename(item['filepath']))[0]
                
                processed_images.append(tensor_img)
                processed_cond_images.append(cond_tensor)
                image_keys.append(image_key)
                
            except Exception as e:
                print(f"è­¦å‘Š: å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™ {item['filepath']}: {e}")
                # åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„é»‘è‰²å›¾ç‰‡ä½œä¸ºæ›¿ä»£
                default_img = torch.zeros(3, target_dims[1], target_dims[0])
                default_cond_img = torch.zeros(3, target_dims[1] // downsample_factor, target_dims[0] // downsample_factor)
                default_key = f"error_{len(processed_images)}"
                
                processed_images.append(default_img)
                processed_cond_images.append(default_cond_img)
                image_keys.append(default_key)
            
        # 3. å°†æ‰€æœ‰å¤„ç†å¥½çš„å›¾ç‰‡å †å æˆä¸€ä¸ªæ‰¹æ¬¡
        return {
            'image': torch.stack(processed_images),  # ä¿æŒä¸ S3 æ•°æ®æ ¼å¼ä¸€è‡´
            'cond_image': torch.stack(processed_cond_images),  # ä¿æŒä¸ S3 æ•°æ®æ ¼å¼ä¸€è‡´
            '__key__': image_keys
        }
        
    print(f"âœ… å·²åˆ›å»º Collate Functionï¼Œä¸‹é‡‡æ ·å€ç‡: {downsample_factor}")
    return collate_fn


def create_dataloader(image_folder_path, base_size=1024, multiple_of=32, batch_size=4, 
                     num_workers=4, drop_last=False, downsample_factor=2, upsample_factor=1, shuffle=True, max_samples=None):
    """
    åˆ›å»ºå®Œæ•´çš„ DataLoaderã€‚
    
    Args:
        image_folder_path: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        base_size: åŸºç¡€å°ºå¯¸
        multiple_of: å°ºå¯¸å¿…é¡»æ˜¯è¯¥æ•°çš„å€æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: å·¥ä½œè¿›ç¨‹æ•°
        drop_last: æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡
        downsample_factor (int): ä¸‹é‡‡æ ·å€ç‡ï¼Œé»˜è®¤ä¸º2
        upsample_factor (int): ä¸Šé‡‡æ ·å€ç‡ï¼Œé»˜è®¤ä¸º1
        shuffle (bool): æ˜¯å¦éšæœºåŒ–é¡ºåºï¼ŒTrueä¸ºè®­ç»ƒæ¨¡å¼ï¼ŒFalseä¸ºéªŒè¯æ¨¡å¼
        max_samples (int): æœ€å¤§å›¾åƒæ•°é‡ï¼Œç”¨äºoverfittingæ—¶é™åˆ¶æ•°æ®é›†å¤§å°
    
    Returns:
        DataLoader: é…ç½®å¥½çš„æ•°æ®åŠ è½½å™¨
    """
    print("ğŸš€ å¼€å§‹åˆ›å»º DataLoader...")
    print(f"ä¸‹é‡‡æ ·å€ç‡: {downsample_factor}, multiple_of: {multiple_of}")
    print(f"éšæœºåŒ–æ¨¡å¼: {'è®­ç»ƒæ¨¡å¼ï¼ˆéšæœºï¼‰' if shuffle else 'éªŒè¯æ¨¡å¼ï¼ˆå›ºå®šé¡ºåºï¼‰'}")
    if max_samples is not None:
        print(f"ğŸ”’ Overfittingæ¨¡å¼ï¼šé™åˆ¶ä½¿ç”¨å‰ {max_samples} å¼ å›¾åƒ")
    
    # 1. åˆ›å»ºæ¡¶
    print("(1/5) åˆ›å»ºå®½é«˜æ¯”æ¡¶...")
    buckets = create_aspect_ratio_buckets(base_size=base_size, multiple_of=multiple_of)
    
    # 2. åˆ›å»ºæ•°æ®é›†
    print("(2/5) åˆ›å»ºæ•°æ®é›†...")
    dataset = AspectRatioBucketDataset(image_folder_path=image_folder_path, buckets=buckets, max_samples=max_samples)
    
    if len(dataset) == 0:
        raise ValueError(f"åœ¨ {image_folder_path} ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶")
    
    # 3. åˆ›å»ºé‡‡æ ·å™¨
    print("(3/5) åˆ›å»ºé‡‡æ ·å™¨...")
    batch_sampler = AspectRatioBucketSampler(dataset, batch_size=batch_size, drop_last=drop_last, shuffle=shuffle)
    
    # 4. åˆ›å»º collate å‡½æ•°
    print("(4/5) åˆ›å»º collate å‡½æ•°...")
    collate_function = create_collate_fn(buckets, downsample_factor=downsample_factor, upsample_factor=upsample_factor)
    
    # 5. åˆ›å»º DataLoader
    print("(5/5) åˆ›å»º DataLoader...")
    dataloader = DataLoader(
        dataset=dataset,
        batch_sampler=batch_sampler,
        collate_fn=collate_function,
        num_workers=num_workers
    )
    
    print(f"âœ… DataLoader åˆ›å»ºå®Œæˆï¼æ•°æ®é›†å¤§å°: {len(dataset)}, æ‰¹æ¬¡æ•°é‡: {len(batch_sampler)}")
    return dataloader


def test_dataloader(image_folder_path, num_epochs=2, max_batches=5, downsample_factor=2):
    """
    æµ‹è¯• DataLoader çš„åŠŸèƒ½ã€‚
    
    Args:
        image_folder_path: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        num_epochs: æµ‹è¯•çš„è½®æ•°
        max_batches: æ¯è½®æœ€å¤šæµ‹è¯•çš„æ‰¹æ¬¡æ•°é‡
        downsample_factor (int): ä¸‹é‡‡æ ·å€ç‡ï¼Œé»˜è®¤ä¸º2
    """
    print(f"ğŸ§ª å¼€å§‹æµ‹è¯• DataLoader...")
    print(f"å›¾ç‰‡æ–‡ä»¶å¤¹: {image_folder_path}")
    print(f"ä¸‹é‡‡æ ·å€ç‡: {downsample_factor}")
    
    try:
        # åˆ›å»º DataLoader
        dataloader = create_dataloader(
            image_folder_path=image_folder_path,
            base_size=1024,
            multiple_of=32,
            batch_size=2,
            num_workers=0,  # æµ‹è¯•æ—¶ä½¿ç”¨å•è¿›ç¨‹
            drop_last=True,
            downsample_factor=downsample_factor
        )
        
        # æµ‹è¯•è®­ç»ƒå¾ªç¯
        for epoch in range(num_epochs):
            print(f"\n--- ç¬¬ {epoch+1} è½®æµ‹è¯• ---")
            for i, batch in enumerate(dataloader):
                if i >= max_batches:
                    break
                    
                images_tensor = batch['image']  # ä¿æŒä¸ S3 æ•°æ®æ ¼å¼ä¸€è‡´
                cond_images_tensor = batch['cond_image']  # æ¡ä»¶å›¾åƒ
                print(f"æ‰¹æ¬¡ {i+1}:")
                print(f"  åŸå§‹å›¾åƒå½¢çŠ¶: {images_tensor.shape}")
                print(f"  æ¡ä»¶å›¾åƒå½¢çŠ¶: {cond_images_tensor.shape}")
                print(f"  æ•°æ®ç±»å‹: {images_tensor.dtype}")
                print(f"  æ•°å€¼èŒƒå›´: [{images_tensor.min():.3f}, {images_tensor.max():.3f}]")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ NaN æˆ–æ— ç©·å¤§å€¼
                if torch.isnan(images_tensor).any():
                    print("  è­¦å‘Š: æ£€æµ‹åˆ° NaN å€¼!")
                if torch.isinf(images_tensor).any():
                    print("  è­¦å‘Š: æ£€æµ‹åˆ°æ— ç©·å¤§å€¼!")
                    
        print("\nâœ… DataLoader æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # é…ç½®å‚æ•°
    BASE_SIZE = 512
    MULTIPLE_OF = 64
    BATCH_SIZE = 4
    DOWNSAMPLE_FACTOR = 4  # æµ‹è¯•4å€ä¸‹é‡‡æ ·
    IMAGE_FOLDER = '/mnt/localssd/data/LSDIR/train/HR'  # è¯·ä¿®æ”¹ä¸ºæ‚¨çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
    
    # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(IMAGE_FOLDER):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {IMAGE_FOLDER}")
        print("è¯·ä¿®æ”¹ IMAGE_FOLDER å˜é‡ä¸ºæœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„")
    else:
        # è¿è¡Œæµ‹è¯•
        test_dataloader(IMAGE_FOLDER, num_epochs=2, max_batches=3, downsample_factor=DOWNSAMPLE_FACTOR)
